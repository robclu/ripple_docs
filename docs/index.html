


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Welcome to Ripple’s documentation! &mdash; Ripple 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/collapsible-lists/css/tree_view.css" type="text/css" />
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="Ripple API" href="api/ripple_api_root.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://github.com/robclu/ripple" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="">Get Started</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://github.com/roblcu/ripple">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          <div class="version">
            1.0.0
          </div>
          
          

          


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/ripple_api_root.html">Ripple API</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="performance/saxpy.html">Saxpy Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance/particle_update.html">Particle Update Performance</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="#">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Welcome to Ripple’s documentation!</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <div class="section" id="welcome-to-ripple-s-documentation">
<h1>Welcome to Ripple’s documentation!<a class="headerlink" href="#welcome-to-ripple-s-documentation" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/ripple_api_root.html">Ripple API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/ripple_api_root.html#class-hierarchy">Class Hierarchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ripple_api_root.html#file-hierarchy">File Hierarchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ripple_api_root.html#full-api">Full API</a></li>
</ul>
</li>
</ul>
</div>
<p>Ripple is a framework designed to make parallelization of large-scale
heterogeneous applications simple, with a focus on multiple gpus systems.
It is designed to reduce the difficulty of GPGPU programming, without
sacrificing performance.</p>
<p>Currently it will use all available computational resources on a node (any
number of CPUs and/or GPUs) and is currently being extended to support
multi-node systems.</p>
<p>The target compute unit is the GPU, since it offers far superior performance
compared to even large numbers of CPU cores, however, the user has a choice of
which to use, and can use both, concurrently, if desired.</p>
<p>Ripple uses a number of abstractions to facilitate the above, which allow for
simple, expressive code to run in parallel across many large systems (it has
been used to run physics simulations on grids consisting of billions of cells).</p>
<p>The interface for specifying computational flow is the graph interface, which
allows computational operations and dependencies to be specified expressively
and concisely, and from which ripple can determine efficient parallelization.
The graph interface scales well, and can scale up to 7.3x for 8 V100 GPUs for
non-trivial real-world problems</p>
<p>The documentation contains the API, main features, examples, and tutorials.</p>
<div class="section" id="building-ripple">
<h2>Building Ripple<a class="headerlink" href="#building-ripple" title="Permalink to this headline">¶</a></h2>
<p>First, get ripple from github: <a class="reference external" href="https://github.com/robclu/ripple">ripple</a></p>
<p>Currently, Ripple <strong>requires</strong> CUDA, since some of the features require it,
however, we are in the process of removing the CUDA dependency for the CPU only
use case . Ripple has the following dependencies:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">cmake</span> <span class="o">&gt;=</span> <span class="mf">3.19</span>
<span class="n">clang</span> <span class="o">&gt;=</span> <span class="mf">9.0</span> <span class="n">with</span> <span class="n">CUDA</span> <span class="o">&gt;=</span> <span class="mf">9.0</span> <span class="n">or</span>
<span class="n">gcc</span>   <span class="o">&gt;=</span> <span class="mf">6.0</span> <span class="n">with</span> <span class="n">CUDA</span> <span class="o">&gt;=</span> <span class="mf">11.0</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ripple is written using C++ &gt;= 17, which is why CUDA &gt;= 11.0 is required if
used as the device compiler, where as clang &gt;= 9.0 has C++-17 support and can
be used as both the host and device compiler.</p>
</div>
<p>Ripple is built using cmake, specifying various options. To see all available
options for building ripple, from the project root, run</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">cmake</span> <span class="o">-</span><span class="n">DPRINT_OPTIONS</span><span class="o">=</span><span class="n">ON</span> <span class="p">.</span>
</pre></div>
</div>
<p>which shows the required and optional options.</p>
<p>Cmake support for CUDA does not always work as expected, so to build ripple,
the paths to the variable compilers, as well as cuda installation, need to be
specified:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="n">build</span> <span class="o">&amp;&amp;</span> <span class="n">cd</span> <span class="n">build</span>
<span class="n">cmake</span>  \
  <span class="o">-</span><span class="n">DCMAKE_CUDA_COMPILER</span><span class="o">=&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">cuda</span> <span class="n">compiler</span><span class="o">&gt;</span> \
  <span class="o">-</span><span class="n">DCMAKE_CXX_COMPILER</span><span class="o">=&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">cxx</span> <span class="n">compiler</span><span class="o">&gt;</span>   \
  <span class="o">-</span><span class="n">DCUDA_PATH</span><span class="o">=&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">cuda</span> <span class="n">toolkit</span> <span class="n">root</span><span class="o">&gt;</span>       \
  <span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span>                    \
  <span class="o">-</span><span class="n">DCUDA_ARCHS</span><span class="o">=</span><span class="mi">80</span><span class="p">;</span><span class="mi">86</span>                            \
  <span class="p">..</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Of the above parameters, the first three are <strong>required</strong>, while
the rest are optional.</p>
<p>If the cuda compiler is clang, then the CXX compiler is automatically set to
clang as well.</p>
<p>If the cuda compiler is set to nvcc, the cuda host compiler will be set to the
<code class="code docutils literal notranslate"><span class="pre">CMAKE_CXX_COMPILER</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="code docutils literal notranslate"><span class="pre">-DCMAKE_BUILD_TYPE=Debug</span></code>, the cmake language feature sometimes
fails to correctly verify that the cuda compiler is correct and working. The
current fix for this is to first specify the build parameters as above using
<code class="code docutils literal notranslate"><span class="pre">-DCMAKE_BUILD_TYPE=Release</span></code>, and then simply execute
<code class="code docutils literal notranslate"><span class="pre">-DCMAKE_BUILD_TYPE=Debug</span> <span class="pre">..</span></code> after.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ripple will print out the complete build configuration at the end of the
cmake command, so you can verify that the chosen parameters are correct.</p>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>The shortest code to help with getting started is the SAXPY example,
which is as simple as the following:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">ripple</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">size_x</span>       <span class="o">=</span> <span class="mi">1000000</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">partitions_x</span> <span class="o">=</span> <span class="n">topology</span><span class="p">().</span><span class="n">num_gpus</span><span class="p">();</span>

<span class="c1">// Create the tensors. Partitions is always a vector, with each component</span>
<span class="c1">// specifying the number of partitions in the {x, y, z} dimension. Each</span>
<span class="c1">// partition will be reside and therefore execute on a separate gpu.</span>
<span class="n">Tensor</span> <span class="n">a</span><span class="p">{{</span><span class="n">partitions</span><span class="p">},</span> <span class="n">size_x</span><span class="p">};</span>
<span class="n">Tensor</span> <span class="n">b</span><span class="p">{{</span><span class="n">partitions</span><span class="p">},</span> <span class="n">size_x</span><span class="p">};</span>
<span class="n">Tensor</span> <span class="n">c</span><span class="p">{{</span><span class="n">partitions</span><span class="p">},</span> <span class="n">size_x</span><span class="p">};</span>
<span class="kt">float</span> <span class="n">x</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>

<span class="c1">// Create the graph, which splits the execution across the partitions of the</span>
<span class="c1">// tensor. The arguments to the functors are iterators which point to the</span>
<span class="c1">// cell in the tensor at the global thread indices.</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">Graph</span> <span class="n">graph</span><span class="p">;</span>
<span class="n">graph</span><span class="p">.</span><span class="n">split</span><span class="p">([]</span> <span class="n">ripple_host_device</span> <span class="p">(</span><span class="k">auto</span> <span class="n">a</span><span class="p">,</span> <span class="k">auto</span> <span class="n">b</span><span class="p">,</span> <span class="k">auto</span> <span class="n">c</span><span class="p">,</span> <span class="kt">float</span> <span class="n">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Set a and b to thread indices:</span>
  <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">global_idx</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">());</span>
  <span class="o">*</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">global_idx</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">());</span>

  <span class="c1">// Set the result:</span>
  <span class="o">*</span><span class="n">c</span> <span class="o">=</span> <span class="o">*</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="o">*</span><span class="n">b</span><span class="p">;</span>
<span class="p">},</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">x</span><span class="p">);</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">execute</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span>

<span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">c</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">());</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fmt</span><span class="o">::</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;{} {}</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">c</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Ripple has a lot more functionality, and the next best wat to explore some of
it is to have a look through the benchmarks, which can be found in
<code class="code docutils literal notranslate"><span class="pre">benchmarks/</span></code>. If you want to build the benchmarks, then add
<code class="code docutils literal notranslate"><span class="pre">-DRIPPLE_BUILD_BENCHMARKS=ON</span></code> to the cmake configuration.</p>
<p>There is a lot more in depth information, which can be found through the
following links:</p>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Performance:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="performance/saxpy.html">Saxpy Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance/particle_update.html">Particle Update Performance</a></li>
</ul>
</div>
</div>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h2>
<p>There are three main components in ripple which provide all the functionality
and hence features for simple parallel programming. They all work together, and
are tensors, polymorphic data layout, and graphs. Each is given a brief
overview here, but see the additional links for more detailed information and
examples. Here we illustrate the main concepts with a simple example which
computes the dot product of a vector with itself, and then computes the finite
difference of the results. This is a contrived example, and real world examples
can be found in the <code class="code docutils literal notranslate"><span class="pre">benchmarks/</span></code> folder, but it illustrates the concepts
and is simple.</p>
<div class="section" id="tensors">
<h3>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h3>
<p>Tensors are and extension of arrays to multiple dimensions, and are used to
define the space on which computation is performed, they are templated over the
data type and the number of dimensions, similar to <code class="code docutils literal notranslate"><span class="pre">std::array</span></code>, but with
dynamic dimension sizes. The full use of tensors is only achieved when combined
with graphs, to define the operations on the tensors, and also with user-defined
classes which have polymorphic data layout.</p>
<p>For our example, we will define a 2D tensor with 1000x1000 elements, with
padding element on each side of each dimension, so 1002x1002 total elements,
with a custom vector class, which we will define in the next section. We also
partition the tensor in the y dimension across all gpus.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Alias for SoA (strided) tensor:</span>
<span class="k">using</span> <span class="n">SoATensor</span> <span class="o">=</span> <span class="n">ripple</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="n">Vec2</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="n">ripple</span><span class="o">::</span><span class="n">strided_view</span><span class="o">&gt;</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">;</span>

<span class="c1">// To create an AoS (contiguous) tensor is as simple as:</span>
<span class="k">using</span> <span class="n">AoSTensor</span> <span class="o">=</span> <span class="n">ripple</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&lt;</span><span class="n">Vec2</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="n">ripple</span><span class="o">::</span><span class="n">contiguous_view</span><span class="o">&gt;</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">;</span>

<span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">size_x</span>  <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">size_y</span>  <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span> <span class="n">partitions</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="n">ripple</span><span class="o">::</span><span class="n">topology</span><span class="p">().</span><span class="n">num_gpus</span><span class="p">()};</span>

<span class="c1">// Create the tensors</span>
<span class="n">SoATensor</span> <span class="nf">soa_x</span><span class="p">(</span><span class="n">partitions</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">size_x</span><span class="p">,</span> <span class="n">size_y</span><span class="p">);</span>
<span class="n">SoATensor</span> <span class="nf">soa_y</span><span class="p">(</span><span class="n">partitions</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">size_x</span><span class="p">,</span> <span class="n">size_y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="polymorphic-data-layout">
<h3>Polymorphic Data layout<a class="headerlink" href="#polymorphic-data-layout" title="Permalink to this headline">¶</a></h3>
<p>For GPU codes, struct of array (SoA) data layout usually provided better
performance since it results in coalesced memory access, and therefore less
memory transactions and higher memory bandwidth. However, SoA can make software
development difficult, so ripple enables user defined classes to have
polymorphic data layout, through a template parameters, which when used with a
tensor, will store the data as either SoA or AoS, allowing Object Oriented
classes but good performance, as well as being able to test the actual effects
on performance by changing only a few lines of code.</p>
<p>For our example, we will define the vector to have a polymorphic layout:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// T      : Type of the data</span>
<span class="c1">// Layout : The layout of the data</span>
<span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="p">,</span> <span class="k">typename</span> <span class="n">Layout</span><span class="o">&gt;</span>
<span class="k">struct</span> <span class="nl">Vec2</span> <span class="p">:</span> <span class="n">ripple</span><span class="o">::</span><span class="n">PolymorphicLayout</span><span class="o">&lt;</span><span class="n">Vec2</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">Layout</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
  <span class="c1">// Required by ripple, define that we want 2 elements of type T.</span>
  <span class="k">using</span> <span class="n">Desc</span>    <span class="o">=</span> <span class="n">ripple</span><span class="o">::</span><span class="n">StorageDescriptor</span><span class="o">&lt;</span><span class="n">L</span><span class="p">,</span> <span class="n">ripple</span><span class="o">::</span><span class="n">Vector</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;&gt;</span><span class="p">;</span>
  <span class="k">using</span> <span class="n">Storage</span> <span class="o">=</span> <span class="k">typename</span> <span class="n">Desc</span><span class="o">::</span><span class="n">Storage</span><span class="p">;</span>

  <span class="c1">// Actual storage, like an array.</span>
  <span class="n">Storage</span> <span class="n">storage</span><span class="p">;</span>

  <span class="c1">// Return the x component:</span>
  <span class="k">auto</span> <span class="nf">x</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="o">&amp;</span> <span class="p">{</span>
    <span class="c1">// Static index syntax:</span>
    <span class="c1">//</span>
    <span class="c1">// Index of element in type ---|</span>
    <span class="c1">// Type index in storage ---|  |</span>
    <span class="c1">//                          |  |</span>
    <span class="c1">//                          |  |</span>
    <span class="c1">//                          v  v</span>
    <span class="k">return</span> <span class="n">storage</span><span class="p">.</span><span class="k">template</span> <span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="p">}</span>

  <span class="c1">// Return the x component:</span>
  <span class="k">auto</span> <span class="nf">y</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="o">&amp;</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">storage</span><span class="p">.</span><span class="k">template</span> <span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="p">}</span>

  <span class="c1">// Get the Ith element:</span>
  <span class="k">auto</span> <span class="k">operator</span><span class="p">[](</span><span class="kt">size_t</span> <span class="n">i</span><span class="p">)</span> <span class="k">const</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="o">&amp;</span> <span class="p">{</span>
    <span class="c1">// Dynamic index syntax:</span>
    <span class="c1">//</span>
    <span class="c1">// Index of element in type --|</span>
    <span class="c1">// Type index in storage      |</span>
    <span class="c1">//                 |          |</span>
    <span class="c1">//                 |   |------|</span>
    <span class="c1">//                 v   v</span>
    <span class="k">return</span> <span class="n">storage</span><span class="p">.</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">OtherLayout</span><span class="o">&gt;</span>
  <span class="k">auto</span> <span class="n">dot</span><span class="p">(</span><span class="k">const</span> <span class="n">Vec2</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">OtherLayout</span><span class="o">&gt;&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="k">const</span> <span class="o">-&gt;</span> <span class="n">T</span> <span class="p">{</span>
    <span class="k">return</span>
      <span class="n">storage</span><span class="p">.</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">*</span> <span class="n">other</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
      <span class="n">storage</span><span class="p">.</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">*</span> <span class="n">other</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</div>
<div class="section" id="graphs">
<h3>Graphs<a class="headerlink" href="#graphs" title="Permalink to this headline">¶</a></h3>
<p>Graphs are essentially the glue which bring it all together. They define the way
that the tensor data is transformed, through function objects which operate on
the tensor data, and allow the dependencies and memory transfer operations to
be specified between the operations.</p>
<p>All this results in a framework where a complete GPGPU program can be written
entriely in C++ with a very minimal knowledge of GPU programming. The only real
change of mindset is that functors must be written to operate on a single
element in the tensor, so there is no looping.</p>
<p>Lastly, for out example, define the graph which performs the dot product
and then the central difference.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here the boundary elements (elements next to the padding cells) will be invalid because the padding cells don’t compute the dot product. Ripple
has a number of features to handle these situations, however, for simplicity,
we don’t include that here.</p>
</div>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Note, we could initialze the graph as</span>
<span class="c1">// ripple::Graph graph(ripple::ExecutionKind::Gpu)</span>
<span class="c1">// to default to gpu execution.</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">Graph</span> <span class="n">graph</span><span class="p">;</span>

<span class="c1">// Step 1: Intialize all data to have a thread index sum:</span>
<span class="n">graph</span><span class="p">.</span><span class="n">split</span><span class="p">(</span>
  <span class="n">ripple</span><span class="o">::</span><span class="n">ExecutionKind</span><span class="o">::</span><span class="n">Gpu</span><span class="p">,</span>
  <span class="p">[]</span> <span class="n">ripple_host_device</span> <span class="p">(</span><span class="k">auto</span> <span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span><span class="o">-&gt;</span><span class="n">x</span><span class="p">()</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">global_idx</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">());</span>
    <span class="n">x</span><span class="o">-&gt;</span><span class="n">y</span><span class="p">()</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">global_idx</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimy</span><span class="p">());</span>
  <span class="p">},</span> <span class="n">soa_x</span><span class="p">);</span>

<span class="c1">// Step 2: Set y to the dot product of x with itself:</span>
<span class="c1">// This must be submitted after the previous operation, hence then_split</span>
<span class="n">graph</span><span class="p">.</span><span class="n">then_split</span><span class="p">(</span>
  <span class="n">ripple</span><span class="o">::</span><span class="n">ExecutionKind</span><span class="o">::</span><span class="n">Gpu</span><span class="p">,</span>
  <span class="p">[]</span> <span class="n">ripple_host_device</span> <span class="p">(</span><span class="k">auto</span> <span class="n">x</span><span class="p">,</span> <span class="k">auto</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">const</span> <span class="kt">float</span> <span class="n">dot</span> <span class="o">=</span> <span class="n">x</span><span class="o">-&gt;</span><span class="n">dot</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">);</span>
    <span class="n">y</span><span class="o">-&gt;</span><span class="n">x</span><span class="p">()</span> <span class="o">=</span> <span class="n">dot</span><span class="p">;</span>
    <span class="n">y</span><span class="o">-&gt;</span><span class="n">y</span><span class="p">()</span> <span class="o">=</span> <span class="n">dot</span><span class="p">;</span>
<span class="p">},</span> <span class="n">soa_x</span><span class="p">,</span> <span class="n">soa_y</span><span class="p">);</span>

<span class="c1">// Step 3: Set x to the central difference using y.</span>
<span class="c1">// Because there is a partition, we use concurrent data access, which will</span>
<span class="c1">// perform a copy of the padding data from neighbouring partitions (i.e, the</span>
<span class="c1">// neighbour dot product result computed on any adjacent cells on a different</span>
<span class="c1">// gpu:</span>
<span class="n">graph</span><span class="p">.</span><span class="n">then_split</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">ExecutionKind</span><span class="o">::</span><span class="n">Gpu</span><span class="p">,</span>
  <span class="p">[]</span> <span class="n">ripple_host_device</span> <span class="p">(</span><span class="k">auto</span> <span class="n">x</span><span class="p">,</span> <span class="k">auto</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">x</span><span class="o">-&gt;</span><span class="n">x</span><span class="p">()</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">y</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimx</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">x</span><span class="o">-&gt;</span><span class="n">y</span><span class="p">()</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimy</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">y</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">ripple</span><span class="o">::</span><span class="n">dimy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
<span class="p">},</span> <span class="n">soa_x</span><span class="p">,</span> <span class="n">ripple</span><span class="o">::</span><span class="n">concurrent_padded_access</span><span class="p">(</span><span class="n">soa_y</span><span class="p">));</span>

<span class="c1">// Graph is done, just needs execution:</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">execute</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="n">ripple</span><span class="o">::</span><span class="n">fence</span><span class="p">();</span> <span class="c1">// wait until finished</span>
</pre></div>
</div>
</div>
</div>
</div>


              </article>
              
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="api/ripple_api_root.html" class="btn btn-neutral float-right" title="Ripple API" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-2021, Rob Clucas.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Welcome to Ripple’s documentation!</a><ul>
<li><a class="reference internal" href="#building-ripple">Building Ripple</a></li>
<li><a class="reference internal" href="#getting-started">Getting Started</a></li>
<li><a class="reference internal" href="#features">Features</a><ul>
<li><a class="reference internal" href="#tensors">Tensors</a></li>
<li><a class="reference internal" href="#polymorphic-data-layout">Polymorphic Data layout</a></li>
<li><a class="reference internal" href="#graphs">Graphs</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
  <script src="_static/jquery.js"></script>
  <script src="_static/underscore.js"></script>
  <script src="_static/doctools.js"></script>
  <script src="_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
  <script src="_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
  <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for Ripple</p>
          <a class="with-right-arrow" href="">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get tutorials to help with understand all features</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Examples</h2>
          <p>Find examples to help get started</p>
          <a class="with-right-arrow" href="">View Examples</a>
        </div>
      </div>
    </div>
  </div>

  <!---
  <footer class="site-footer">
    <!---
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://github.com/robclu/ripple" class="footer-logo"></a>
      </div>
    </div>
  </footer>
  --->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/flex-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://github.com/robclu/ripple" aria-label="Ripple"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="">Get Started</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <li>
            <a href="https://github.com/roblcu/ripple">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>